# [템플릿] AI Agent용 제품 개발 워크플로우 (듀얼 트랙 적용)

## 문서 개요

이 문서는 기존의 안정적인 **Delivery(구현)** 워크플로우를 유지하되, 제품의 시장 적합성(Product-Market Fit)과 사용자 만족도를 높이기 위해 **Discovery(검증 및 학습)** 트랙을 통합한 **듀얼 트랙 개발 방법론**을 정의합니다.

**목표:** **"올바른 것을 잘 만들기(Building the right thing well)"**

---

## 1. 듀얼 트랙 개발 구조 정의

| 트랙 명 | 목표 | 주요 활동 | 산출물 (Gate) |
| :--- | :--- | :--- | :--- |
| **Discovery** (발견) | **무엇을 만들지** 결정 (문제/솔루션 검증) | JTBD, 가설 설정, 사용자 인터뷰, 클릭 프로토타입 테스트 | **Phase 0**으로의 입력 (검증된 `spec`과 `target metric`) |
| **Delivery** (구현) | **정해진 것을 정확하게** 만들기 | TDD 기반 설계, 코딩, 테스트, 배포 (기존 Phase 0~9) | 배포된 코드 및 사용자 데이터 |

**규칙:** Discovery 트랙에서 검증이 완료된 **최소 기능 명세(MVP Scope)**만이 Delivery 트랙(Phase 0)으로 넘어갈 수 있습니다.

---

## 2. **Phase -1 (신설): 제품 발견 및 가설 검증**

**Template:** `prompt/templete/-1. discovery.md`
**Output:** `/docs/discovery/{date}-{feature}/`

기술 스택을 정하기 전에, **만들고자 하는 기능이 사용자에게 가치 있는가**를 최소 비용으로 검증합니다.

### 2.1. 필수 산출물 (Phase 0 진입 게이트)

| 산출물 | 핵심 내용 (AI Agent 대상) |
| :--- | :--- |
| **A. JTBD 문제 요약** | **누가**, **언제**, **무엇을** 하려는데 **무엇이 막는가** (기능 중심 X, 과업 중심 O) |
| **B. 가설 카드 (Assumption/Test Card)** | **가설:** "X 페르소나는 Y를 원할 것이다." **검증 방법:** (예: 5명 문제 인터뷰, 1일짜리 프로토타입) **성공 기준:** **숫자 한 줄** (예: 이탈률 < 15%, SUS 점수 > 70점) |
| **C. 타겟 지표 (NSM)** | **제품의 북극성 지표(NSM)**와 **해당 기능의 AARRR 지표** 1개를 명확히 정의 (예: 활성 과업 완료 수/주) |
| **D. Go/No-Go 의사결정** | 가설의 성공 기준 충족 여부 기록. **성공 시에만 Phase 0로 이동.** |

### 2.2. 필수 검증 활동 (최소 5인 대상)

1.  **문제 인터뷰 (The Mom Test 방식):** 사용자의 과거 행동/대안/비용에 집중 (솔루션 제안 X).
2.  **클릭 프로토타입 테스트:** Figma 등으로 **핵심 과업 1개**만 빠르게 구성하여 **사용성(Usability)** 검증.

---

## 3. **기존 Delivery 워크플로우 통합 및 수정**

기존의 체계적인 Phase 0~9 구조를 유지하되, Discovery의 결과를 **반드시 반영**하도록 수정합니다.

| Phase | 수정 내용 (Discovery 반영) |
| :--- | :--- |
| **Phase 0 (Requirements Input)** | 인풋의 `<goal>`은 **Phase -1에서 검증된 가설**을 기반으로 작성. 막연한 기획 의도 금지. |
| **Phase 3 (PRD Creation)** | **[Problem], [Evidence], [Target Metric]** 섹션을 PRD 상단에 의무화하여 **Phase -1 산출물** 인라인. |
| **Phase 4 (User Flow Design)** | User Flow 확정 전에 **P0.5 클릭 프로토타입 테스트**를 완료하고 그 결과를 바탕으로 상세 User Flow를 디자인. |
| **Phase 5 (DB Schema Design)** | **AARRR 지표 측정**을 위한 **핵심 이벤트 로그 테이블/필드**를 DB 스키마에 필수로 포함. |
| **Phase 9 (Implementation)** | **A. TDD 외 필수 작업:** 모든 핵심 기능에 **애널리틱스 이벤트 로깅** 코드 삽입. **B. 배포:** **Feature Toggle/Ladder Release**를 기본으로 적용 (1% $\rightarrow$ 5% $\rightarrow$ 20% 순차 노출). |

---

## 4. **Phase 10 (신설): 측정 및 학습 (Measure & Learn)**

Phase 9의 구현 및 배포 후, 반드시 **학습을 다음 Phase 0의 인풋**으로 연결해야 합니다.

**Output:** `/docs/learning/{date}-{feature}/회고.md`

| 활동 | 핵심 내용 (AI Agent 대상) |
| :--- | :--- |
| **지표 측정** | Phase -1에서 정의한 **Target Metric** 달성 여부 (예: 전환율, 리텐션) 확인. |
| **사용성 회고** | 5명 퍼스트 런 테스트 재실시 후, **사용자 막힘 포인트** 목록화. |
| **의사결정** | **데이터 기반**으로 다음 조치 결정: 1) **반복/개선**, 2) **보류**, 3) **폐기**. (목표 미달 시 폐기를 주저하지 말 것) |

---

## 5. AI Agent 실행 규칙 요약

| 규칙 | 상세 지침 |
| :--- | :--- |
| **Discovery Gate** | Phase -1의 **Target Metric 성공** 없이는 **절대** Phase 0로 진입하지 않는다. |
| **MVP/Iteration** | **가장 핵심 과업 1개**에 집중하여 개발하고, **최대 2주** 내에 사용자에게 배포하여 측정한다. |
| **데이터 중심** | 모든 `Phase 3: PRD`에는 **검증된 증거(Evidence)**와 **목표 수치(Target Metric)**가 포함되어야 한다. |
| **TDD/계측 병행** | Phase 9 구현 시, TDD를 통한 기능 구현과 **애널리틱스 이벤트 계측(Tracking)** 구현을 병행한다. |